{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7da34fb",
   "metadata": {},
   "source": [
    "# House Price Prediction: Model Development and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb6f4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5442e",
   "metadata": {},
   "source": [
    "Various models were trained using datasets subjected to different preprocessing techniques, including splitting with and without standardization and normalization. Upon evaluating the performance across the three datasets—standardized, normalized, and the raw split dataset—the most favorable results were obtained from the dataset without any standardization or normalization. Consequently, for the purpose of this demonstration, the raw split dataset has been selected for loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b5be9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved datasets\n",
    "train_file_path = 'processed_data/split_data/train_data.csv'\n",
    "val_file_path = 'processed_data/split_data/val_data.csv'\n",
    "test_file_path = 'processed_data/split_data/test_data.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_file_path)\n",
    "val_df = pd.read_csv(val_file_path)\n",
    "test_df = pd.read_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9bd0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target variable (y) for each dataset\n",
    "target_column_name = 'price_in_lakhs'\n",
    "X_train, y_train = train_df.drop(target_column_name, axis=1), train_df[target_column_name]\n",
    "X_val, y_val = val_df.drop(target_column_name, axis=1), val_df[target_column_name]\n",
    "X_test, y_test = test_df.drop(target_column_name, axis=1), test_df[target_column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e2ef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary of models to try\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Support Vector Machine': SVR()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d4424b",
   "metadata": {},
   "source": [
    "Hyperparameter tuning is actively pursued to optimize model performance and enhance predictive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52a506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyperparameters for Linear Regression...\n",
      "Best hyperparameters for Linear Regression: {}\n",
      "\n",
      "Tuning hyperparameters for Decision Tree...\n",
      "Best hyperparameters for Decision Tree: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "\n",
      "Tuning hyperparameters for Random Forest...\n",
      "Best hyperparameters for Random Forest: {'max_depth': 30, 'n_estimators': 60}\n",
      "\n",
      "Tuning hyperparameters for Support Vector Machine...\n",
      "Best hyperparameters for Support Vector Machine: {'C': 1000, 'gamma': 0.01}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optional: Hyperparameter tuning using GridSearchCV for specific models\n",
    "param_grid = {\n",
    "    'Linear Regression': {},\n",
    "    'Random Forest': {'n_estimators': [50, 60, 80, 100, 150, 200], 'max_depth': [None, 10, 15, 20, 30]},\n",
    "    'Decision Tree': {'max_depth': [None, 5, 10, 15, 20], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]},\n",
    "    'Support Vector Machine': {'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001]},\n",
    "}\n",
    "\n",
    "# Dictionary to store the best models\n",
    "best_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name in param_grid:\n",
    "        print(f'Tuning hyperparameters for {name}...')\n",
    "        param_search = GridSearchCV(model, param_grid[name], scoring='neg_mean_squared_error', cv=5)\n",
    "        param_search.fit(X_train, y_train)\n",
    "        best_params = param_search.best_params_\n",
    "        print(f'Best hyperparameters for {name}: {best_params}\\n')\n",
    "        \n",
    "        # Redefine the model with the best hyperparameters\n",
    "        best_model = model.__class__(**best_params)\n",
    "        best_models[name] = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328c4e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': LinearRegression(),\n",
       " 'Decision Tree': DecisionTreeRegressor(max_depth=10, min_samples_leaf=2),\n",
       " 'Random Forest': RandomForestRegressor(max_depth=30, n_estimators=60),\n",
       " 'Support Vector Machine': SVR(C=1000, gamma=0.01)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models #best models and thier hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd6386b",
   "metadata": {},
   "source": [
    "Train and Evaluate models along with thier best hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "935135e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression...\n",
      "Mean Squared Error on Validation Set: 0.03714947667611415\n",
      "Linear Regression model saved to saved_models/20231129_125247/Linear Regression_model.pkl\n",
      "\n",
      "Training Decision Tree...\n",
      "Mean Squared Error on Validation Set: 0.05057965238456952\n",
      "Decision Tree model saved to saved_models/20231129_125247/Decision Tree_model.pkl\n",
      "\n",
      "Training Random Forest...\n",
      "Mean Squared Error on Validation Set: 0.030898949190345155\n",
      "Random Forest model saved to saved_models/20231129_125247/Random Forest_model.pkl\n",
      "\n",
      "Training Support Vector Machine...\n",
      "Mean Squared Error on Validation Set: 0.01839588658272734\n",
      "Support Vector Machine model saved to saved_models/20231129_125247/Support Vector Machine_model.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to create a folder if it doesn't exist\n",
    "def create_folder_if_not_exists(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "# Create a folder for saved models if not exists\n",
    "saved_models_folder = 'saved_models'\n",
    "create_folder_if_not_exists(saved_models_folder)\n",
    "\n",
    "# Create a sub-folder based on date-time\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_folder = os.path.join(saved_models_folder, timestamp)\n",
    "create_folder_if_not_exists(model_folder)\n",
    "\n",
    "# Model training and evaluation\n",
    "for name, model in best_models.items():\n",
    "    print(f'Training {name}...')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_val, y_val_pred)\n",
    "    print(f'Mean Squared Error on Validation Set: {mse}')\n",
    "    \n",
    "    # Optionally, you can save the trained model for future use\n",
    "    model_save_path = os.path.join(model_folder, f'{name}_model.pkl')\n",
    "    \n",
    "    with open(model_save_path, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "    \n",
    "    print(f'{name} model saved to {model_save_path}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4515e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved models\n",
    "loaded_models = {}\n",
    "for name in best_models.keys():\n",
    "    model_path = os.path.join(model_folder, f'{name}_model.pkl')\n",
    "    \n",
    "    with open(model_path, 'rb') as file:\n",
    "        loaded_model = pickle.load(file)\n",
    "    \n",
    "    loaded_models[name] = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb5ad5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression on the test set...\n",
      "Mean Squared Error on Test Set (Linear Regression): 0.05607257834191994\n",
      "\n",
      "Evaluating Decision Tree on the test set...\n",
      "Mean Squared Error on Test Set (Decision Tree): 0.08326471528478133\n",
      "\n",
      "Evaluating Random Forest on the test set...\n",
      "Mean Squared Error on Test Set (Random Forest): 0.06713350286676603\n",
      "\n",
      "Evaluating Support Vector Machine on the test set...\n",
      "Mean Squared Error on Test Set (Support Vector Machine): 0.031126915531599814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame({'Actual': y_test})\n",
    "\n",
    "# Make predictions on the test set and compare against y_test values\n",
    "for name, loaded_model in loaded_models.items():\n",
    "    print(f'Evaluating {name} on the test set...')\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_test_pred = loaded_model.predict(X_test)\n",
    "    \n",
    "    # Add predicted values to the DataFrame\n",
    "    results_df[f'{name}_Predicted'] = y_test_pred\n",
    "    \n",
    "    # Calculate and add MSE to the DataFrame\n",
    "    mse = mean_squared_error(y_test, y_test_pred)\n",
    "    print(f'Mean Squared Error on Test Set ({name}): {mse}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "516cef18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Price in Lakhs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Linear Regression_Predicted</th>\n",
       "      <th>Decision Tree_Predicted</th>\n",
       "      <th>Random Forest_Predicted</th>\n",
       "      <th>Support Vector Machine_Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>187.00</td>\n",
       "      <td>204.087548</td>\n",
       "      <td>171.604776</td>\n",
       "      <td>170.965460</td>\n",
       "      <td>187.941672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.00</td>\n",
       "      <td>39.061007</td>\n",
       "      <td>33.121721</td>\n",
       "      <td>38.442133</td>\n",
       "      <td>36.904572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.00</td>\n",
       "      <td>94.741664</td>\n",
       "      <td>88.996296</td>\n",
       "      <td>88.521821</td>\n",
       "      <td>79.883553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87.00</td>\n",
       "      <td>97.124548</td>\n",
       "      <td>60.870833</td>\n",
       "      <td>77.844596</td>\n",
       "      <td>88.513928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>177.00</td>\n",
       "      <td>110.450276</td>\n",
       "      <td>114.026084</td>\n",
       "      <td>108.205301</td>\n",
       "      <td>152.170656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>118.00</td>\n",
       "      <td>98.964500</td>\n",
       "      <td>115.893114</td>\n",
       "      <td>103.860853</td>\n",
       "      <td>106.926997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45.75</td>\n",
       "      <td>84.383471</td>\n",
       "      <td>50.346776</td>\n",
       "      <td>66.713167</td>\n",
       "      <td>74.036462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>58.95</td>\n",
       "      <td>74.041713</td>\n",
       "      <td>83.498521</td>\n",
       "      <td>86.427271</td>\n",
       "      <td>55.107940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>53.99</td>\n",
       "      <td>45.995800</td>\n",
       "      <td>43.472098</td>\n",
       "      <td>43.353998</td>\n",
       "      <td>48.607860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>80.00</td>\n",
       "      <td>87.233672</td>\n",
       "      <td>80.802999</td>\n",
       "      <td>83.405646</td>\n",
       "      <td>82.292426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>82.10</td>\n",
       "      <td>105.552762</td>\n",
       "      <td>93.488094</td>\n",
       "      <td>89.178705</td>\n",
       "      <td>88.533571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>175.00</td>\n",
       "      <td>193.067858</td>\n",
       "      <td>149.459297</td>\n",
       "      <td>200.976820</td>\n",
       "      <td>147.815729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>79.30</td>\n",
       "      <td>79.337821</td>\n",
       "      <td>65.498747</td>\n",
       "      <td>70.553895</td>\n",
       "      <td>73.951798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>68.00</td>\n",
       "      <td>77.950640</td>\n",
       "      <td>114.026084</td>\n",
       "      <td>104.679839</td>\n",
       "      <td>101.060542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>39.49</td>\n",
       "      <td>30.473447</td>\n",
       "      <td>33.121721</td>\n",
       "      <td>34.923470</td>\n",
       "      <td>35.062819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>47.00</td>\n",
       "      <td>38.709038</td>\n",
       "      <td>33.121721</td>\n",
       "      <td>37.786604</td>\n",
       "      <td>44.295062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>45.50</td>\n",
       "      <td>42.935635</td>\n",
       "      <td>33.121721</td>\n",
       "      <td>36.901401</td>\n",
       "      <td>39.185527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>55.26</td>\n",
       "      <td>51.735347</td>\n",
       "      <td>63.003523</td>\n",
       "      <td>56.075066</td>\n",
       "      <td>53.350272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>33.50</td>\n",
       "      <td>38.942655</td>\n",
       "      <td>40.472883</td>\n",
       "      <td>41.879781</td>\n",
       "      <td>35.929410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>460.00</td>\n",
       "      <td>323.843341</td>\n",
       "      <td>231.379001</td>\n",
       "      <td>257.871490</td>\n",
       "      <td>334.601760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual  Linear Regression_Predicted  Decision Tree_Predicted  \\\n",
       "0   187.00                   204.087548               171.604776   \n",
       "1    40.00                    39.061007                33.121721   \n",
       "2    73.00                    94.741664                88.996296   \n",
       "3    87.00                    97.124548                60.870833   \n",
       "4   177.00                   110.450276               114.026084   \n",
       "5   118.00                    98.964500               115.893114   \n",
       "6    45.75                    84.383471                50.346776   \n",
       "7    58.95                    74.041713                83.498521   \n",
       "8    53.99                    45.995800                43.472098   \n",
       "9    80.00                    87.233672                80.802999   \n",
       "10   82.10                   105.552762                93.488094   \n",
       "11  175.00                   193.067858               149.459297   \n",
       "12   79.30                    79.337821                65.498747   \n",
       "13   68.00                    77.950640               114.026084   \n",
       "14   39.49                    30.473447                33.121721   \n",
       "15   47.00                    38.709038                33.121721   \n",
       "16   45.50                    42.935635                33.121721   \n",
       "17   55.26                    51.735347                63.003523   \n",
       "18   33.50                    38.942655                40.472883   \n",
       "19  460.00                   323.843341               231.379001   \n",
       "\n",
       "    Random Forest_Predicted  Support Vector Machine_Predicted  \n",
       "0                170.965460                        187.941672  \n",
       "1                 38.442133                         36.904572  \n",
       "2                 88.521821                         79.883553  \n",
       "3                 77.844596                         88.513928  \n",
       "4                108.205301                        152.170656  \n",
       "5                103.860853                        106.926997  \n",
       "6                 66.713167                         74.036462  \n",
       "7                 86.427271                         55.107940  \n",
       "8                 43.353998                         48.607860  \n",
       "9                 83.405646                         82.292426  \n",
       "10                89.178705                         88.533571  \n",
       "11               200.976820                        147.815729  \n",
       "12                70.553895                         73.951798  \n",
       "13               104.679839                        101.060542  \n",
       "14                34.923470                         35.062819  \n",
       "15                37.786604                         44.295062  \n",
       "16                36.901401                         39.185527  \n",
       "17                56.075066                         53.350272  \n",
       "18                41.879781                         35.929410  \n",
       "19               257.871490                        334.601760  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display results in a dataframe\n",
    "print(\"--- Price in Lakhs ---\")\n",
    "results_df = np.expm1(results_df)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781cced1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
